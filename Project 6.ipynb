{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '../Mod 6 Project/Data/Train'\n",
    "test_data_dir = '../Mod 6 Project/Data/Test2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 images belonging to 43 classes.\n",
      "Found 12630 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "                    train_data_dir,\n",
    "                    target_size=(64,64),\n",
    "                    classes=[],\n",
    "                    batch_size=39209)\n",
    "\n",
    "test_batches = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "                    test_data_dir,\n",
    "                    target_size=(64,64),\n",
    "                    classes=[],\n",
    "                    batch_size=12630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = next(train_batches)\n",
    "test_data, test_labels = next(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Test.csv')\n",
    "df_train = pd.read_csv('Train.csv')\n",
    "\n",
    "test_df = df['ClassId'].astype('str')\n",
    "train_df = df_train['ClassId'].astype('str')\n",
    "test_labels_df = test_df.str.get_dummies()\n",
    "train_labels_df = train_df.str.get_dummies()\n",
    "\n",
    "test_labels = test_labels_df.values\n",
    "train_labels = train_labels_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: (12630, 64, 64, 3)\n",
      "test label: (12630, 43)\n",
      "train data: (39209, 64, 64, 3)\n",
      "train label: (39209, 43)\n"
     ]
    }
   ],
   "source": [
    "print('test data: {}'.format(test_data.shape))\n",
    "print('test label: {}'.format(test_labels.shape))\n",
    "print('train data: {}'.format(train_data.shape))\n",
    "print('train label: {}'.format(train_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "\n",
    "# train_labels = to_categorical(train_labels)\n",
    "# test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '10': 2,\n",
       " '11': 3,\n",
       " '12': 4,\n",
       " '13': 5,\n",
       " '14': 6,\n",
       " '15': 7,\n",
       " '16': 8,\n",
       " '17': 9,\n",
       " '18': 10,\n",
       " '19': 11,\n",
       " '2': 12,\n",
       " '20': 13,\n",
       " '21': 14,\n",
       " '22': 15,\n",
       " '23': 16,\n",
       " '24': 17,\n",
       " '25': 18,\n",
       " '26': 19,\n",
       " '27': 20,\n",
       " '28': 21,\n",
       " '29': 22,\n",
       " '3': 23,\n",
       " '30': 24,\n",
       " '31': 25,\n",
       " '32': 26,\n",
       " '33': 27,\n",
       " '34': 28,\n",
       " '35': 29,\n",
       " '36': 30,\n",
       " '37': 31,\n",
       " '38': 32,\n",
       " '39': 33,\n",
       " '4': 34,\n",
       " '40': 35,\n",
       " '41': 36,\n",
       " '42': 37,\n",
       " '5': 38,\n",
       " '6': 39,\n",
       " '7': 40,\n",
       " '8': 41,\n",
       " '9': 42}"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(43, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_68 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                589888    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 43)                2795      \n",
      "=================================================================\n",
      "Total params: 649,003\n",
      "Trainable params: 649,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_val = train_data_final[:10000]\n",
    "# partial_x_train = train_data_final[10000:]\n",
    "\n",
    "# y_val = train_labels_final[:10000]\n",
    "# partial_y_train = train_labels_final[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "39209/39209 [==============================] - 89s 2ms/step - loss: 3.5206 - accuracy: 0.0548\n",
      "Epoch 2/5\n",
      "39209/39209 [==============================] - 85s 2ms/step - loss: 3.4908 - accuracy: 0.0560\n",
      "Epoch 3/5\n",
      " 4096/39209 [==>...........................] - ETA: 1:20 - loss: 3.5083 - accuracy: 0.0552"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-587-6cb3ea843605>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                     \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                     batch_size=256)\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    train_labels,  \n",
    "                    epochs=5, \n",
    "                    batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 9s 700us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03847980871796608"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "predictions_transfer = model.predict(test_data)\n",
    "predictions_transfer = np.around(predictions_transfer)\n",
    "f1_score(test_labels, predictions_transfer, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGVdJREFUeJzt3X2QVfWd5/H3F9AAPmUEZmJs6CYr2cRVWrSjiVp5GMxKZlK4hFmjdmKMSahsrcFMUtllFkeRxFSeahKpceNgVCaxFzaYkWGzbsyU6M7mydjGhxGMJSJP8YlgVFgWH+C7f9zLoWmb7gb69LlNv19Vt+45v3s499tX7/3c8/vdc36RmUiSBDCi6gIkSY3DUJAkFQwFSVLBUJAkFQwFSVLBUJAkFQwFSVLBUJAkFQwFSVJhVNUFHKjx48dnS0tL1WVI0pDywAMP/D4zJ/S13ZALhZaWFjo7O6suQ5KGlIjY0J/t7D6SJBUMBUlSwVCQJBUMBUlSobRQiIhbIuL5iHh0P49HRCyKiLUR8UhEnF5WLZKk/inzSGEJMKOXxz8ETKnf5gDfLbEWSRqyOjqgpQVGjKjdd3SU91ylhUJm/jPwQi+bXAB8P2t+Bbw5Ik4oqx6pkQ3mm946hlYdHR0wZw5s2ACZtfs5c0qsJTNLuwEtwKP7eezHwLld1u8G2vra5xlnnJHSQLrttszm5syI2v1ttw3+848dm1l7y9duY8dah3XUNDfvW8OeW3Pzge0H6Mz+fG73Z6ODvfURCv+zh1A4Yz/bzgE6gc5JkyYd2CuhhlX1h/GeGqp+4w/Um946Ds86InquI+LA9tPfUIjatuWIiBbgx5l5Sg+P/R1wb2Yura8/Drw/M5/pbZ9tbW3pGc1D355D4h079raNHQuLF0N7++DV0dJSOxzvrrkZ1q8fnBpGjKi9zbuLgN27B6cG62jcOgbq/9GIeCAz2/rarsqfpK4ELq3/CundwEt9BYIGRiP0k86fv28gQG19/vzBrWPjxgNrL8OkSQfWbh3Dq47rrqt9Yepq7Nhaeyn6czhxMDdgKfAM8BqwGfgU8Fngs/XHA7gBeBL4F/oxnpDpmMKhaoTuksyBOyQ+VI3QRdAo/02sozHr2FPLoXa10ghjCmXcDIVD0wgfgo1UR6O88RthfMU6GreOgdDfUCh1TKEMjikcmkbpJ22UMYU9tcyfX+symjSpdlg+2DVIZRsKYwqqQKP0k7a31wKgubkWSM3N1QTCnlrWr6+F4vr1BoKGN0NhmBn0Qate+GEsNR5DYRA1wq9+GukbuqTGM+RmXhuquveh7zlVHQb/A7m93RCQ1DOPFAZJo/wuX5J6YygMkkY4SUqS+mIoDJJG+dWPJPXGUBgkjfSrH0naH0NhkPirH0lDgb8+GkT+6kdSo/NIQZJUMBQkSQVDQZJUMBQkSQVDQZJUGFahsGBB1RVIUmMbVqFw7bVVVyBJjW1YhYIkqXeHfSgsWFA7gziitr5n2a4kSXqjYTVHc0TP8xNL0uHOOZolSQdsWIXCNddUXYEkNbZhFQqOI0hS74ZVKEiSemcoSJIKhoIkqWAoSJIKhoIkqWAoSJIKhoIkqVBqKETEjIh4PCLWRsS8Hh6fFBH3RMSDEfFIRPxZmfVIknpXWihExEjgBuBDwMnAxRFxcrfNrgJ+mJnTgIuA/1pWPZKkvpV5pHAmsDYz12Xmq8Ay4IJu2yRwbH35OODpEuuRJPVhVIn7PhHY1GV9M3BWt20WAD+NiM8BRwHnlViPJKkPZR4pRA9t3S9cfTGwJDObgD8DfhARb6gpIuZERGdEdG7ZsqWEUiVJUG4obAYmdllv4o3dQ58CfgiQmb8ERgPju+8oMxdnZltmtk2YMKGkciVJZYbC/cCUiJgcEUdSG0he2W2bjcB0gIh4J7VQ8FBAkipSWihk5uvAFcBdwGPUfmW0OiIWRsTM+mZfBD4TEQ8DS4HLcqhNBSdJh5EyB5rJzDuBO7u1Xd1leQ1wTpk1SJL6b1ic0dzRAS0tMGJE7b6jo+qKJKkxlXqk0Ag6OmDOHNixo7a+YUNtHaC9vbq6JKkRHfZHCvPn7w2EPXbsqLVLkvZ12IfCxo0H1i5Jw9lhHwqTJh1YuyQNZ4d9KFx3HYwdu2/b2LG1dknSvg77UGhvh8WLobkZImr3ixc7yCxJPTnsf30EtQAwBCSpb4f9kYIkqf8MBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBUMBUlSwVCQJBVKDYWImBERj0fE2oiYt59tLoyINRGxOiL+W5n1SJJ6N6qsHUfESOAG4IPAZuD+iFiZmWu6bDMF+CvgnMz8Q0T8cVn1SJL6VuaRwpnA2sxcl5mvAsuAC7pt8xnghsz8A0BmPl9iPZKkPpQZCicCm7qsb663dfV24O0R8fOI+FVEzCixHklSH0rrPgKih7bs4fmnAO8HmoD/ExGnZOaL++woYg4wB2DSpEkDX6kkCSj3SGEzMLHLehPwdA/b/GNmvpaZTwGPUwuJfWTm4sxsy8y2CRMmlFawJA13ZYbC/cCUiJgcEUcCFwEru22zAvgAQESMp9adtK7EmiRJvSit+ygzX4+IK4C7gJHALZm5OiIWAp2ZubL+2L+NiDXALuBLmbm1rJokNbbXXnuNzZs3s3PnzqpLGbJGjx5NU1MTRxxxxEH9+8js3s3f2Nra2rKzs7PqMiSV4KmnnuKYY45h3LhxRPQ0LKneZCZbt25l27ZtTJ48eZ/HIuKBzGzrax+e0SypYezcudNAOAQRwbhx4w7pSMtQkNRQDIRDc6ivn6EgSV0cffTRVZdQKUNB0pC3YEHVFRw+DAVJQ96115a7/w0bNjB9+nSmTp3K9OnT2bhxIwDLly/nlFNOobW1lfe+970ArF69mjPPPJPTTjuNqVOn8sQTT5Rb3ADrVyhExL+KiDfVl98fEXMj4s3lliZJjeGKK67g0ksv5ZFHHqG9vZ25c+cCsHDhQu666y4efvhhVq6snYZ14403cuWVV/LQQw/R2dlJU1NTlaUfsP4eKfwI2BURJwE3A5MBL3MtqTILFkBE7QZ7l8voSvrlL3/JJZdcAsDHP/5xfvaznwFwzjnncNlll3HTTTexa9cuAN7znvfw1a9+la9//ets2LCBMWPGDHxBJepvKOzOzNeBWcB3MvMvgRPKK0uSerdgAWTWbrB3eTDGF/b8wufGG2/kK1/5Cps2beK0005j69atXHLJJaxcuZIxY8Zw/vnns2rVqvILGkD9DYXXIuJi4BPAj+ttB3e6nCQNMWeffTbLli0DoKOjg3PPPReAJ598krPOOouFCxcyfvx4Nm3axLp163jb297G3LlzmTlzJo888kiVpR+w/l7m4pPAZ4HrMvOpiJgM3FZeWZLUf9dcM3D72rFjxz7jAF/4whdYtGgRl19+Od/85jeZMGECt956KwBf+tKXeOKJJ8hMpk+fTmtrK1/72te47bbbOOKII3jLW97C1VdfPXDFDYIDvsxFRPwRMDEzK4k/L3MhHb4ee+wx3vnOd1ZdxpDX0+s4oJe5iIh7I+LYiDgeeBi4NSL+5qCqlSQ1rP6OKRyXmS8DHwFuzcwzgPPKK0uSVIX+hsKoiDgBuJC9A82SpMNMf0NhIbW5D57MzPsj4m3A0DpNT5LUp379+igzlwPLu6yvA2aXVZQkqRr9HWhuiog7IuL5iHguIn4UEUPr3G1JUp/62310K7X5ld8KnAj8j3qbJB127rjjDiKC3/72t1WXMuj6GwoTMvPWzHy9flsCTCixLknqU0cHtLTAiBG1+46Ogdnv0qVLOffcc4uzmMuw51pJjaa/ofD7iPhYRIys3z4GbC2zMEnqTUcHzJkDGzbUrnm0YUNt/VCDYfv27fz85z/n5ptv3icUvvGNb3DqqafS2trKvHnzAFi7di3nnXcera2tnH766Tz55JPce++9fPjDHy7+3RVXXMGSJUsAaGlpYeHChZx77rksX76cm266iXe96120trYye/ZsduzYAcBzzz3HrFmzaG1tpbW1lV/84hf89V//Nddff32x3/nz57No0aJD+2N70N/LXFwO/C3wbSCBX1C79IUkVWL+fKh/hhZ27Ki1t7cf/H5XrFjBjBkzePvb387xxx/Pb37zG5577jlWrFjBfffdx9ixY3nhhRcAaG9vZ968ecyaNYudO3eye/duNm3a1Ov+R48eXVxldevWrXzmM58B4KqrruLmm2/mc5/7HHPnzuV973sfd9xxB7t27WL79u289a1v5SMf+QhXXnklu3fvZtmyZfz6178++D90P/r766ONwMyubRHxeeA7A16RJPVDfZ6bfrf319KlS/n85z8PwEUXXcTSpUvZvXs3n/zkJxk7diwAxx9/PNu2beN3v/sds2bNAmof9v3x0Y9+tFh+9NFHueqqq3jxxRfZvn07559/PgCrVq3i+9//PgAjR47kuOOO47jjjmPcuHE8+OCDPPfcc0ybNo1x48Yd2h/bg/4eKfTkCxgKkioyaVKty6in9oO1detWVq1axaOPPkpEsGvXLiKC2bNnF5fL3mN/140bNWoUu3fvLtZ37ty5z+NHHXVUsXzZZZexYsUKWltbWbJkCffee2+v9X36059myZIlPPvss1x++eUH+Nf1z6FMxxl9byJJ5bjuOqh/cS+MHVtrP1i33347l156KRs2bGD9+vVs2rSJyZMnc/zxx3PLLbcUff4vvPACxx57LE1NTaxYsQKAV155hR07dtDc3MyaNWt45ZVXeOmll7j77rv3+3zbtm3jhBNO4LXXXqOjy2DI9OnT+e53vwvUBqRffvllAGbNmsVPfvIT7r///uKoYqAdSigc2OVVJWkAtbfD4sXQ3Fybca25ubZ+KOMJS5cuLbqD9pg9ezZPP/00M2fOpK2tjdNOO41vfetbAPzgBz9g0aJFTJ06lbPPPptnn32WiRMncuGFFzJ16lTa29uZNm3afp/vy1/+MmeddRYf/OAHecc73lG0X3/99dxzzz2ceuqpnHHGGaxevRqAI488kg984ANceOGFjBw58uD/0F70eunsiNhGzx/+AYzJzEPpfjooXjpbOnx56eze7d69m9NPP53ly5czZcqU/W5X2qWzM/OYzDy2h9sxVQSCJA1Xa9as4aSTTmL69Om9BsKh8oNdkoaAk08+mXXr1pX+PIcypiBJOswYCpIayoFOEax9HerrZyhIahijR49m69atBsNByky2bt3a7xPpelLqmEJEzACuB0YC38vMr+1nu7+gNl/DuzLTnxZJw1RTUxObN29my5YtVZcyZI0ePZqmpoOf2aC0UIiIkcANwAeBzcD9EbEyM9d02+4YYC5wX1m1SBoajjjiCCZPnlx1GcNamd1HZwJrM3NdZr4KLAMu6GG7LwPfAHb28JgkaRCVGQonAl0vF7i53laIiGnAxMz8cYl1SJL6qcxQ6OnaSMXoUUSMoHYp7i/2uaOIORHRGRGd9jVKUnnKDIXNwMQu603A013WjwFOAe6NiPXAu4GVEfGG07Azc3FmtmVm24QJTvgmSWUpMxTuB6ZExOSIOBK4iNo8zwBk5kuZOT4zWzKzBfgVMNNfH0lSdUoLhcx8HbgCuAt4DPhhZq6OiIURMbP3fy1JqkKp5ylk5p3And3art7Ptu8vsxZJUt88o1mSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ0GSVDAUJEkFQ6ECCxZUXYEk9azUUIiIGRHxeESsjYh5PTz+hYhYExGPRMTdEdFcZj2N4tprq65AknpWWihExEjgBuBDwMnAxRFxcrfNHgTaMnMqcDvwjbLqkST1rcwjhTOBtZm5LjNfBZYBF3TdIDPvycwd9dVfAU0l1lOpBQsgonaDvct2JUlqJGWGwonApi7rm+tt+/Mp4H/19EBEzImIzojo3LJlywCWOHgWLIDM2g32LhsKkhpJmaEQPbRljxtGfAxoA77Z0+OZuTgz2zKzbcKECQNYoiSpq1El7nszMLHLehPwdPeNIuI8YD7wvsx8pcR6GsY111RdgST1rMwjhfuBKRExOSKOBC4CVnbdICKmAX8HzMzM50uspaHYZSSpUZUWCpn5OnAFcBfwGPDDzFwdEQsjYmZ9s28CRwPLI+KhiFi5n91JkgZBmd1HZOadwJ3d2q7usnxemc8vSTowntEsSSoYCpKkgqEgSSoYCpKkgqEgSSoYCpKkgqEgSSoYCpKkgqEgSSoYCpKkgqEwjHlhPkndGQrDmHNFS+rOUJAkFQyFYca5oiX1JjJ7nCGzYbW1tWVnZ2fVZRwWIvbOGS3p8BYRD2RmW1/beaQgSSoYCsOYc0VL6s5QGMYcR5DUnaGgyhlOUuMwFFQ5z5eQGoehIEkqGAqqhOdLSI3J8xRUOc+XkMrneQrSAfIoRTIU1AAa5XwJB7wlQ0ENwG/oUuMwFDSsNdqAd6MEZKPUocHnQLNU1wgD3o1QQyPVoYHjQLOkIc8jlsFnKEh1VQ14N0oXVqPU0VWjDP4Pp3Cy+0hqII3SbWMdjVnHggUHH1AN0X0UETMi4vGIWBsR83p4/E0R8d/rj98XES1l1iOp8TXiEUujGIwjp9JCISJGAjcAHwJOBi6OiJO7bfYp4A+ZeRLwbeDrZdUjDQWNcs5GlXUsWFD7Vr7nm/meZbvTBkeZRwpnAmszc11mvgosAy7ots0FwN/Xl28Hpkfs+U8gDT+N8oHTKHVUabiGU5mhcCKwqcv65npbj9tk5uvAS8C47juKiDkR0RkRnVu2bCmpXEmNplGOnKo02OFUZij09I2/+1BNf7YhMxdnZltmtk2YMGFAipPU+BrliGU4hVOZobAZmNhlvQl4en/bRMQo4DjghRJrkqQDNpzCqcxQuB+YEhGTI+JI4CJgZbdtVgKfqC//BbAqh9pvZCVpkAxGOI0qa8eZ+XpEXAHcBYwEbsnM1RGxEOjMzJXAzcAPImIttSOEi8qqR5LUt9JCASAz7wTu7NZ2dZflncC/L7MGSVL/eZkLSVLBUJAkFQwFSVJhyF0QLyK2ABuqruMQjQd+X3URDcTXYy9fi335euzrUF6P5szs80SvIRcKh4OI6OzP1QqHC1+PvXwt9uXrsa/BeD3sPpIkFQwFSVLBUKjG4qoLaDC+Hnv5WuzL12Nfpb8ejilIkgoeKUiSCobCIIqIiRFxT0Q8FhGrI+LKqmuqWkSMjIgHI+LHVddStYh4c0TcHhG/rf8/8p6qa6pSRPxl/X3yaEQsjYjRVdc0WCLiloh4PiIe7dJ2fET8U0Q8Ub//ozKe21AYXK8DX8zMdwLvBv5jD1OUDjdXAo9VXUSDuB74SWa+A2hlGL8uEXEiMBdoy8xTqF1UczhdMHMJMKNb2zzg7sycAtxdXx9whsIgysxnMvM39eVt1N703WejGzYiogn4c+B7VddStYg4FngvtSsHk5mvZuaL1VZVuVHAmPpcK2N543wsh63M/GfeOLdM1+mL/x74d2U8t6FQkYhoAaYB91VbSaW+A/wnYHfVhTSAtwFbgFvr3Wnfi4ijqi6qKpn5O+BbwEbgGeClzPxptVVV7k8y8xmofcEE/riMJzEUKhARRwM/Aj6fmS9XXU8VIuLDwPOZ+UDVtTSIUcDpwHczcxrwfympe2AoqPeXXwBMBt4KHBURH6u2quHBUBhkEXEEtUDoyMx/qLqeCp0DzIyI9cAy4E8j4rZqS6rUZmBzZu45crydWkgMV+cBT2Xmlsx8DfgH4OyKa6racxFxAkD9/vkynsRQGEQREdT6jB/LzL+pup4qZeZfZWZTZrZQG0BclZnD9ptgZj4LbIqIf11vmg6sqbCkqm0E3h0RY+vvm+kM44H3uq7TF38C+McynqTUmdf0BucAHwf+JSIeqrf9l/oMddLngI76nObrgE9WXE9lMvO+iLgd+A21X+09yDA6uzkilgLvB8ZHxGbgGuBrwA8j4lPUQrOUWSs9o1mSVLD7SJJUMBQkSQVDQZJUMBQkSQVDQZJUMBSkuojYFREPdbkN2BnFEdHS9YqXUqPyPAVpr/+XmadVXYRUJY8UpD5ExPqI+HpE/Lp+O6ne3hwRd0fEI/X7SfX2P4mIOyLi4fptz+UZRkbETfU5An4aEWPq28+NiDX1/Syr6M+UAENB6mpMt+6jj3Z57OXMPBP4W2pXd6W+/P3MnAp0AIvq7YuA/52ZrdSuX7S63j4FuCEz/w3wIjC73j4PmFbfz2fL+uOk/vCMZqkuIrZn5tE9tK8H/jQz19UvaPhsZo6LiN8DJ2Tma/X2ZzJzfERsAZoy85Uu+2gB/qk+QQoR8Z+BIzLzKxHxE2A7sAJYkZnbS/5Tpf3ySEHqn9zP8v626ckrXZZ3sXdM78+BG4AzgAfqk8pIlTAUpP75aJf7X9aXf8HeKSLbgZ/Vl+8G/gMUc1Afu7+dRsQIYGJm3kNtwqE3A284WpEGi99IpL3GdLl6LdTmS97zs9Q3RcR91L5IXVxvmwvcEhFfojZr2p6rml4JLK5fzXIXtYB4Zj/PORK4LSKOAwL4ttNwqkqOKUh9qI8ptGXm76uuRSqb3UeSpIJHCpKkgkcKkqSCoSBJKhgKkqSCoSBJKhgKkqSCoSBJKvx/YEh9BTPhSXUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, 11)\n",
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# b+ is for \"blue cross\"\n",
    "plt.plot(epochs, loss, 'b+', label='Loss')\n",
    "plt.plot(epochs, acc, 'bo', label='Accuracy')\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 10 epochs, 256 batch size w/o regularuzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
